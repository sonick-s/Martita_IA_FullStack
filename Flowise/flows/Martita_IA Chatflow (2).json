{
  "nodes": [
    {
      "id": "apiLoader_0",
      "position": {
        "x": -1072.058215900421,
        "y": -691.251922095702
      },
      "type": "customNode",
      "data": {
        "id": "apiLoader_0",
        "label": "API Loader",
        "version": 2.1,
        "name": "apiLoader",
        "type": "Document",
        "baseClasses": [
          "Document"
        ],
        "category": "Document Loaders",
        "description": "Load data from an API",
        "inputParams": [
          {
            "label": "Method",
            "name": "method",
            "type": "options",
            "options": [
              {
                "label": "GET",
                "name": "GET"
              },
              {
                "label": "POST",
                "name": "POST"
              }
            ],
            "id": "apiLoader_0-input-method-options",
            "display": true
          },
          {
            "label": "URL",
            "name": "url",
            "type": "string",
            "id": "apiLoader_0-input-url-string",
            "display": true
          },
          {
            "label": "Headers",
            "name": "headers",
            "type": "json",
            "additionalParams": true,
            "optional": true,
            "id": "apiLoader_0-input-headers-json",
            "display": true
          },
          {
            "label": "SSL Certificate",
            "description": "Please upload a SSL certificate file in either .pem or .crt",
            "name": "caFile",
            "type": "file",
            "fileType": ".pem, .crt",
            "additionalParams": true,
            "optional": true,
            "id": "apiLoader_0-input-caFile-file",
            "display": true
          },
          {
            "label": "Body",
            "name": "body",
            "type": "json",
            "description": "JSON body for the POST request. If not specified, agent will try to figure out itself from AIPlugin if provided",
            "additionalParams": true,
            "optional": true,
            "id": "apiLoader_0-input-body-json",
            "display": true
          },
          {
            "label": "Additional Metadata",
            "name": "metadata",
            "type": "json",
            "description": "Additional metadata to be added to the extracted documents",
            "optional": true,
            "additionalParams": true,
            "id": "apiLoader_0-input-metadata-json",
            "display": true
          },
          {
            "label": "Omit Metadata Keys",
            "name": "omitMetadataKeys",
            "type": "string",
            "rows": 4,
            "description": "Each document loader comes with a default set of metadata keys that are extracted from the document. You can use this field to omit some of the default metadata keys. The value should be a list of keys, seperated by comma. Use * to omit all metadata keys execept the ones you specify in the Additional Metadata field",
            "placeholder": "key1, key2, key3.nestedKey1",
            "optional": true,
            "additionalParams": true,
            "id": "apiLoader_0-input-omitMetadataKeys-string",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Text Splitter",
            "name": "textSplitter",
            "type": "TextSplitter",
            "optional": true,
            "id": "apiLoader_0-input-textSplitter-TextSplitter",
            "display": true
          }
        ],
        "inputs": {
          "textSplitter": "",
          "method": "GET",
          "url": "http://backend:8000/construir-tramite/estructurado",
          "headers": "",
          "body": "",
          "metadata": "",
          "omitMetadataKeys": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "Array of document objects containing metadata and pageContent",
            "options": [
              {
                "id": "apiLoader_0-output-document-Document|json",
                "name": "document",
                "label": "Document",
                "description": "Array of document objects containing metadata and pageContent",
                "type": "Document | json"
              },
              {
                "id": "apiLoader_0-output-text-string|json",
                "name": "text",
                "label": "Text",
                "description": "Concatenated string from pageContent of documents",
                "type": "string | json"
              }
            ],
            "default": "document"
          }
        ],
        "outputs": {
          "output": "document"
        },
        "selected": false
      },
      "width": 300,
      "height": 509,
      "selected": false,
      "positionAbsolute": {
        "x": -1072.058215900421,
        "y": -691.251922095702
      },
      "dragging": false
    },
    {
      "id": "chatGoogleGenerativeAI_0",
      "position": {
        "x": 40.337594456548516,
        "y": -840.620612307978
      },
      "type": "customNode",
      "data": {
        "id": "chatGoogleGenerativeAI_0",
        "label": "ChatGoogleGenerativeAI",
        "version": 3,
        "name": "chatGoogleGenerativeAI",
        "type": "ChatGoogleGenerativeAI",
        "baseClasses": [
          "ChatGoogleGenerativeAI",
          "LangchainChatGoogleGenerativeAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "chatGoogleGenerativeAI_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gemini-1.5-flash-latest",
            "id": "chatGoogleGenerativeAI_0-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Custom Model Name",
            "name": "customModelName",
            "type": "string",
            "placeholder": "gemini-1.5-pro-exp-0801",
            "description": "Custom model name to use. If provided, it will override the model selected",
            "additionalParams": true,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-customModelName-string",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Output Tokens",
            "name": "maxOutputTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-maxOutputTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topP-number",
            "display": true
          },
          {
            "label": "Top Next Highest Probability Tokens",
            "name": "topK",
            "type": "number",
            "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topK-number",
            "display": true
          },
          {
            "label": "Harm Category",
            "name": "harmCategory",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_attribute_definitions\">official guide</a> on how to use Harm Category",
            "options": [
              {
                "label": "Dangerous",
                "name": "HARM_CATEGORY_DANGEROUS_CONTENT"
              },
              {
                "label": "Harassment",
                "name": "HARM_CATEGORY_HARASSMENT"
              },
              {
                "label": "Hate Speech",
                "name": "HARM_CATEGORY_HATE_SPEECH"
              },
              {
                "label": "Sexually Explicit",
                "name": "HARM_CATEGORY_SEXUALLY_EXPLICIT"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-harmCategory-multiOptions",
            "display": true
          },
          {
            "label": "Harm Block Threshold",
            "name": "harmBlockThreshold",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_setting_thresholds\">official guide</a> on how to use Harm Block Threshold",
            "options": [
              {
                "label": "Low and Above",
                "name": "BLOCK_LOW_AND_ABOVE"
              },
              {
                "label": "Medium and Above",
                "name": "BLOCK_MEDIUM_AND_ABOVE"
              },
              {
                "label": "None",
                "name": "BLOCK_NONE"
              },
              {
                "label": "Only High",
                "name": "BLOCK_ONLY_HIGH"
              },
              {
                "label": "Threshold Unspecified",
                "name": "HARM_BLOCK_THRESHOLD_UNSPECIFIED"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-harmBlockThreshold-multiOptions",
            "display": true
          },
          {
            "label": "Base URL",
            "name": "baseUrl",
            "type": "string",
            "description": "Base URL for the API. Leave empty to use the default.",
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-baseUrl-string",
            "display": true
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-allowImageUploads-boolean",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-cache-BaseCache",
            "display": true
          },
          {
            "label": "Context Cache",
            "name": "contextCache",
            "type": "GoogleAICacheManager",
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-contextCache-GoogleAICacheManager",
            "display": true
          }
        ],
        "inputs": {
          "cache": "{{inMemoryCache_0.data.instance}}",
          "contextCache": "",
          "modelName": "gemini-2.5-flash-preview-05-20",
          "customModelName": "",
          "temperature": "0.1",
          "streaming": true,
          "maxOutputTokens": "",
          "topP": "",
          "topK": "",
          "harmCategory": "",
          "harmBlockThreshold": "",
          "baseUrl": "",
          "allowImageUploads": ""
        },
        "outputAnchors": [
          {
            "id": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatGoogleGenerativeAI",
            "label": "ChatGoogleGenerativeAI",
            "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
            "type": "ChatGoogleGenerativeAI | LangchainChatGoogleGenerativeAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 725,
      "selected": false,
      "positionAbsolute": {
        "x": 40.337594456548516,
        "y": -840.620612307978
      },
      "dragging": false
    },
    {
      "id": "faiss_0",
      "position": {
        "x": -497.46459976616774,
        "y": -124.10695411917939
      },
      "type": "customNode",
      "data": {
        "id": "faiss_0",
        "label": "Faiss",
        "version": 1,
        "name": "faiss",
        "type": "Faiss",
        "baseClasses": [
          "Faiss",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "Upsert embedded data and perform similarity search upon query using Faiss library from Meta",
        "inputParams": [
          {
            "label": "Base Path to load",
            "name": "basePath",
            "description": "Path to load faiss.index file",
            "placeholder": "C:\\Users\\User\\Desktop",
            "type": "string",
            "id": "faiss_0-input-basePath-string",
            "display": true
          },
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "faiss_0-input-topK-number",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "faiss_0-input-document-Document",
            "display": true
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "faiss_0-input-embeddings-Embeddings",
            "display": true
          }
        ],
        "inputs": {
          "document": [
            "{{apiLoader_0.data.instance}}"
          ],
          "embeddings": "{{googleGenerativeAiEmbeddings_0.data.instance}}",
          "basePath": "C:\\MARTITA_IA\\datos_docker\\flowise\\uploads",
          "topK": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "faiss_0-output-retriever-Faiss|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Faiss Retriever",
                "description": "",
                "type": "Faiss | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "faiss_0-output-vectorStore-Faiss|SaveableVectorStore|VectorStore",
                "name": "vectorStore",
                "label": "Faiss Vector Store",
                "description": "",
                "type": "Faiss | SaveableVectorStore | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 464,
      "selected": false,
      "positionAbsolute": {
        "x": -497.46459976616774,
        "y": -124.10695411917939
      },
      "dragging": false
    },
    {
      "id": "googleGenerativeAiEmbeddings_0",
      "position": {
        "x": -1049.5507171247905,
        "y": -135.48342025186327
      },
      "type": "customNode",
      "data": {
        "id": "googleGenerativeAiEmbeddings_0",
        "label": "GoogleGenerativeAI Embeddings",
        "version": 2,
        "name": "googleGenerativeAiEmbeddings",
        "type": "GoogleGenerativeAiEmbeddings",
        "baseClasses": [
          "GoogleGenerativeAiEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "Google Generative API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "googleGenerativeAiEmbeddings_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "embedding-001",
            "id": "googleGenerativeAiEmbeddings_0-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Task Type",
            "name": "tasktype",
            "type": "options",
            "description": "Type of task for which the embedding will be used",
            "options": [
              {
                "label": "TASK_TYPE_UNSPECIFIED",
                "name": "TASK_TYPE_UNSPECIFIED"
              },
              {
                "label": "RETRIEVAL_QUERY",
                "name": "RETRIEVAL_QUERY"
              },
              {
                "label": "RETRIEVAL_DOCUMENT",
                "name": "RETRIEVAL_DOCUMENT"
              },
              {
                "label": "SEMANTIC_SIMILARITY",
                "name": "SEMANTIC_SIMILARITY"
              },
              {
                "label": "CLASSIFICATION",
                "name": "CLASSIFICATION"
              },
              {
                "label": "CLUSTERING",
                "name": "CLUSTERING"
              }
            ],
            "default": "TASK_TYPE_UNSPECIFIED",
            "id": "googleGenerativeAiEmbeddings_0-input-tasktype-options",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "embedding-001",
          "tasktype": "TASK_TYPE_UNSPECIFIED"
        },
        "outputAnchors": [
          {
            "id": "googleGenerativeAiEmbeddings_0-output-googleGenerativeAiEmbeddings-GoogleGenerativeAiEmbeddings|Embeddings",
            "name": "googleGenerativeAiEmbeddings",
            "label": "GoogleGenerativeAiEmbeddings",
            "description": "Google Generative API to generate embeddings for a given text",
            "type": "GoogleGenerativeAiEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 472,
      "selected": false,
      "positionAbsolute": {
        "x": -1049.5507171247905,
        "y": -135.48342025186327
      },
      "dragging": false
    },
    {
      "id": "llmFilterRetriever_0",
      "position": {
        "x": 46.970132858161634,
        "y": -46.528202800521115
      },
      "type": "customNode",
      "data": {
        "id": "llmFilterRetriever_0",
        "label": "LLM Filter Retriever",
        "version": 1,
        "name": "llmFilterRetriever",
        "type": "LLMFilterRetriever",
        "baseClasses": [
          "LLMFilterRetriever",
          "BaseRetriever"
        ],
        "category": "Retrievers",
        "description": "Iterate over the initially returned documents and extract, from each, only the content that is relevant to the query",
        "inputParams": [
          {
            "label": "Query",
            "name": "query",
            "type": "string",
            "description": "Query to retrieve documents from retriever. If not specified, user question will be used",
            "optional": true,
            "acceptVariable": true,
            "id": "llmFilterRetriever_0-input-query-string",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Vector Store Retriever",
            "name": "baseRetriever",
            "type": "VectorStoreRetriever",
            "id": "llmFilterRetriever_0-input-baseRetriever-VectorStoreRetriever",
            "display": true
          },
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "llmFilterRetriever_0-input-model-BaseLanguageModel",
            "display": true
          }
        ],
        "inputs": {
          "baseRetriever": "{{faiss_0.data.instance}}",
          "model": "{{chatGoogleGenerativeAI_1.data.instance}}",
          "query": "{x}"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "llmFilterRetriever_0-output-retriever-LLMFilterRetriever|BaseRetriever",
                "name": "retriever",
                "label": "LLM Filter Retriever",
                "description": "",
                "type": "LLMFilterRetriever | BaseRetriever"
              },
              {
                "id": "llmFilterRetriever_0-output-document-Document|json",
                "name": "document",
                "label": "Document",
                "description": "Array of document objects containing metadata and pageContent",
                "type": "Document | json"
              },
              {
                "id": "llmFilterRetriever_0-output-text-string|json",
                "name": "text",
                "label": "Text",
                "description": "Concatenated string from pageContent of documents",
                "type": "string | json"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 413,
      "selected": false,
      "positionAbsolute": {
        "x": 46.970132858161634,
        "y": -46.528202800521115
      },
      "dragging": false
    },
    {
      "id": "chatGoogleGenerativeAI_1",
      "position": {
        "x": -515.3463235071936,
        "y": 411.48172862720537
      },
      "type": "customNode",
      "data": {
        "id": "chatGoogleGenerativeAI_1",
        "label": "ChatGoogleGenerativeAI (1)",
        "version": 3,
        "name": "chatGoogleGenerativeAI",
        "type": "ChatGoogleGenerativeAI",
        "baseClasses": [
          "ChatGoogleGenerativeAI",
          "LangchainChatGoogleGenerativeAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "chatGoogleGenerativeAI_1-input-credential-credential",
            "display": true
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gemini-1.5-flash-latest",
            "id": "chatGoogleGenerativeAI_1-input-modelName-asyncOptions",
            "display": true
          },
          {
            "label": "Custom Model Name",
            "name": "customModelName",
            "type": "string",
            "placeholder": "gemini-1.5-pro-exp-0801",
            "description": "Custom model name to use. If provided, it will override the model selected",
            "additionalParams": true,
            "optional": true,
            "id": "chatGoogleGenerativeAI_1-input-customModelName-string",
            "display": true
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatGoogleGenerativeAI_1-input-temperature-number",
            "display": true
          },
          {
            "label": "Streaming",
            "name": "streaming",
            "type": "boolean",
            "default": true,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-streaming-boolean",
            "display": true
          },
          {
            "label": "Max Output Tokens",
            "name": "maxOutputTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-maxOutputTokens-number",
            "display": true
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-topP-number",
            "display": true
          },
          {
            "label": "Top Next Highest Probability Tokens",
            "name": "topK",
            "type": "number",
            "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-topK-number",
            "display": true
          },
          {
            "label": "Harm Category",
            "name": "harmCategory",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_attribute_definitions\">official guide</a> on how to use Harm Category",
            "options": [
              {
                "label": "Dangerous",
                "name": "HARM_CATEGORY_DANGEROUS_CONTENT"
              },
              {
                "label": "Harassment",
                "name": "HARM_CATEGORY_HARASSMENT"
              },
              {
                "label": "Hate Speech",
                "name": "HARM_CATEGORY_HATE_SPEECH"
              },
              {
                "label": "Sexually Explicit",
                "name": "HARM_CATEGORY_SEXUALLY_EXPLICIT"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-harmCategory-multiOptions",
            "display": true
          },
          {
            "label": "Harm Block Threshold",
            "name": "harmBlockThreshold",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_setting_thresholds\">official guide</a> on how to use Harm Block Threshold",
            "options": [
              {
                "label": "Low and Above",
                "name": "BLOCK_LOW_AND_ABOVE"
              },
              {
                "label": "Medium and Above",
                "name": "BLOCK_MEDIUM_AND_ABOVE"
              },
              {
                "label": "None",
                "name": "BLOCK_NONE"
              },
              {
                "label": "Only High",
                "name": "BLOCK_ONLY_HIGH"
              },
              {
                "label": "Threshold Unspecified",
                "name": "HARM_BLOCK_THRESHOLD_UNSPECIFIED"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-harmBlockThreshold-multiOptions",
            "display": true
          },
          {
            "label": "Base URL",
            "name": "baseUrl",
            "type": "string",
            "description": "Base URL for the API. Leave empty to use the default.",
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_1-input-baseUrl-string",
            "display": true
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Allow image input. Refer to the <a href=\"https://docs.flowiseai.com/using-flowise/uploads#image\" target=\"_blank\">docs</a> for more details.",
            "default": false,
            "optional": true,
            "id": "chatGoogleGenerativeAI_1-input-allowImageUploads-boolean",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatGoogleGenerativeAI_1-input-cache-BaseCache",
            "display": true
          },
          {
            "label": "Context Cache",
            "name": "contextCache",
            "type": "GoogleAICacheManager",
            "optional": true,
            "id": "chatGoogleGenerativeAI_1-input-contextCache-GoogleAICacheManager",
            "display": true
          }
        ],
        "inputs": {
          "cache": "",
          "contextCache": "",
          "modelName": "gemini-2.5-flash-preview-05-20",
          "customModelName": "",
          "temperature": "0.1",
          "streaming": true,
          "maxOutputTokens": "",
          "topP": "",
          "topK": "",
          "harmCategory": "",
          "harmBlockThreshold": "",
          "baseUrl": "",
          "allowImageUploads": ""
        },
        "outputAnchors": [
          {
            "id": "chatGoogleGenerativeAI_1-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatGoogleGenerativeAI",
            "label": "ChatGoogleGenerativeAI",
            "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
            "type": "ChatGoogleGenerativeAI | LangchainChatGoogleGenerativeAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 725,
      "selected": false,
      "positionAbsolute": {
        "x": -515.3463235071936,
        "y": 411.48172862720537
      },
      "dragging": false
    },
    {
      "id": "conversationalRetrievalQAChain_0",
      "position": {
        "x": 648.1237585054141,
        "y": -140.41877701244016
      },
      "type": "customNode",
      "data": {
        "id": "conversationalRetrievalQAChain_0",
        "label": "Conversational Retrieval QA Chain",
        "version": 3,
        "name": "conversationalRetrievalQAChain",
        "type": "ConversationalRetrievalQAChain",
        "baseClasses": [
          "ConversationalRetrievalQAChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
        "inputParams": [
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "conversationalRetrievalQAChain_0-input-returnSourceDocuments-boolean",
            "display": true
          },
          {
            "label": "Rephrase Prompt",
            "name": "rephrasePrompt",
            "type": "string",
            "description": "Using previous chat history, rephrase question into a standalone question",
            "warning": "Prompt must include input variables: {chat_history} and {question}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
            "id": "conversationalRetrievalQAChain_0-input-rephrasePrompt-string",
            "display": true
          },
          {
            "label": "Response Prompt",
            "name": "responsePrompt",
            "type": "string",
            "description": "Taking the rephrased question, search for answer from the provided context",
            "warning": "Prompt must include input variable: {context}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "I want you to act as a document that I am having a conversation with. Your name is \"AI Assistant\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure\" and stop after that. Refuse to answer any question not about the info. Never break character.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure\". Don't try to make up an answer. Never break character.",
            "id": "conversationalRetrievalQAChain_0-input-responsePrompt-string",
            "display": true
          }
        ],
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "conversationalRetrievalQAChain_0-input-model-BaseChatModel",
            "display": true
          },
          {
            "label": "Vector Store Retriever",
            "name": "vectorStoreRetriever",
            "type": "BaseRetriever",
            "id": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
            "display": true
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseMemory",
            "optional": true,
            "description": "If left empty, a default BufferMemory will be used",
            "id": "conversationalRetrievalQAChain_0-input-memory-BaseMemory",
            "display": true
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "conversationalRetrievalQAChain_0-input-inputModeration-Moderation",
            "display": true
          }
        ],
        "inputs": {
          "model": "{{chatGoogleGenerativeAI_0.data.instance}}",
          "vectorStoreRetriever": "{{llmFilterRetriever_0.data.instance}}",
          "memory": "",
          "returnSourceDocuments": true,
          "rephrasePrompt": "\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
          "responsePrompt": "Responde con el contexto que se te pase\n------------\n{context}\n------------",
          "inputModeration": []
        },
        "outputAnchors": [
          {
            "id": "conversationalRetrievalQAChain_0-output-conversationalRetrievalQAChain-ConversationalRetrievalQAChain|BaseChain|Runnable",
            "name": "conversationalRetrievalQAChain",
            "label": "ConversationalRetrievalQAChain",
            "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
            "type": "ConversationalRetrievalQAChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 536,
      "selected": false,
      "positionAbsolute": {
        "x": 648.1237585054141,
        "y": -140.41877701244016
      },
      "dragging": false
    },
    {
      "id": "inMemoryCache_0",
      "position": {
        "x": -327.0671589135739,
        "y": -576.2088702321065
      },
      "type": "customNode",
      "data": {
        "id": "inMemoryCache_0",
        "label": "InMemory Cache",
        "version": 1,
        "name": "inMemoryCache",
        "type": "InMemoryCache",
        "baseClasses": [
          "InMemoryCache",
          "BaseCache"
        ],
        "category": "Cache",
        "description": "Cache LLM response in memory, will be cleared once app restarted",
        "inputParams": [],
        "inputAnchors": [],
        "inputs": {},
        "outputAnchors": [
          {
            "id": "inMemoryCache_0-output-inMemoryCache-InMemoryCache|BaseCache",
            "name": "inMemoryCache",
            "label": "InMemoryCache",
            "description": "Cache LLM response in memory, will be cleared once app restarted",
            "type": "InMemoryCache | BaseCache"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 149,
      "positionAbsolute": {
        "x": -327.0671589135739,
        "y": -576.2088702321065
      },
      "selected": false
    }
  ],
  "edges": [
    {
      "source": "googleGenerativeAiEmbeddings_0",
      "sourceHandle": "googleGenerativeAiEmbeddings_0-output-googleGenerativeAiEmbeddings-GoogleGenerativeAiEmbeddings|Embeddings",
      "target": "faiss_0",
      "targetHandle": "faiss_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "googleGenerativeAiEmbeddings_0-googleGenerativeAiEmbeddings_0-output-googleGenerativeAiEmbeddings-GoogleGenerativeAiEmbeddings|Embeddings-faiss_0-faiss_0-input-embeddings-Embeddings"
    },
    {
      "source": "apiLoader_0",
      "sourceHandle": "apiLoader_0-output-document-Document|json",
      "target": "faiss_0",
      "targetHandle": "faiss_0-input-document-Document",
      "type": "buttonedge",
      "id": "apiLoader_0-apiLoader_0-output-document-Document|json-faiss_0-faiss_0-input-document-Document"
    },
    {
      "source": "chatGoogleGenerativeAI_1",
      "sourceHandle": "chatGoogleGenerativeAI_1-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "llmFilterRetriever_0",
      "targetHandle": "llmFilterRetriever_0-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "chatGoogleGenerativeAI_1-chatGoogleGenerativeAI_1-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable-llmFilterRetriever_0-llmFilterRetriever_0-input-model-BaseLanguageModel"
    },
    {
      "source": "llmFilterRetriever_0",
      "sourceHandle": "llmFilterRetriever_0-output-retriever-LLMFilterRetriever|BaseRetriever",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
      "type": "buttonedge",
      "id": "llmFilterRetriever_0-llmFilterRetriever_0-output-retriever-LLMFilterRetriever|BaseRetriever-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
    },
    {
      "source": "chatGoogleGenerativeAI_0",
      "sourceHandle": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatGoogleGenerativeAI_0-chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-model-BaseChatModel"
    },
    {
      "source": "faiss_0",
      "sourceHandle": "faiss_0-output-retriever-Faiss|VectorStoreRetriever|BaseRetriever",
      "target": "llmFilterRetriever_0",
      "targetHandle": "llmFilterRetriever_0-input-baseRetriever-VectorStoreRetriever",
      "type": "buttonedge",
      "id": "faiss_0-faiss_0-output-retriever-Faiss|VectorStoreRetriever|BaseRetriever-llmFilterRetriever_0-llmFilterRetriever_0-input-baseRetriever-VectorStoreRetriever"
    },
    {
      "source": "inMemoryCache_0",
      "sourceHandle": "inMemoryCache_0-output-inMemoryCache-InMemoryCache|BaseCache",
      "target": "chatGoogleGenerativeAI_0",
      "targetHandle": "chatGoogleGenerativeAI_0-input-cache-BaseCache",
      "type": "buttonedge",
      "id": "inMemoryCache_0-inMemoryCache_0-output-inMemoryCache-InMemoryCache|BaseCache-chatGoogleGenerativeAI_0-chatGoogleGenerativeAI_0-input-cache-BaseCache"
    }
  ]
}